{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fbdb5c",
   "metadata": {},
   "source": [
    "In this notebook, we will build a 3D map of a scene from a small set of images and then localize an image downloaded from the Internet. This demo was contributed by [Philipp Lindenberger](https://github.com/Phil26AT/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_exhaustive,\n",
    ")\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ac394",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Here we define some output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Path(\"datasets/sacre_coeur\")\n",
    "outputs = Path(\"outputs/demo/\")\n",
    "!rm -rf $outputs\n",
    "sfm_pairs = outputs / \"pairs-sfm.txt\"\n",
    "loc_pairs = outputs / \"pairs-loc.txt\"\n",
    "sfm_dir = outputs / \"sfm\"\n",
    "features = outputs / \"features.h5\"\n",
    "matches = outputs / \"matches.h5\"\n",
    "\n",
    "feature_conf = extract_features.confs[\"disk\"]\n",
    "matcher_conf = match_features.confs[\"disk+lightglue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7b21e",
   "metadata": {},
   "source": [
    "# 3D mapping\n",
    "First we list the images used for mapping. These are all day-time shots of Sacre Coeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [p.relative_to(images).as_posix() for p in (images / \"mapping/\").iterdir()]\n",
    "print(len(references), \"mapping images\")\n",
    "plot_images([read_image(images / r) for r in references], dpi=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23739ad",
   "metadata": {},
   "source": [
    "Then we extract features and match them across image pairs. Since we deal with few images, we simply match all pairs exhaustively. For larger scenes, we would use image retrieval, as demonstrated in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.main(\n",
    "    feature_conf, images, image_list=references, feature_path=features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43800511",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.main(\n",
    "    feature_conf, images, image_list=[\"mapping/02928139_3448003521.jpg\"], feature_path=features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_from_exhaustive.main(sfm_pairs, image_list=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9adf4",
   "metadata": {},
   "source": [
    "The we run incremental Structure-From-Motion and display the reconstructed 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52fe785",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reconstruction.main(\n",
    "    sfm_dir, images, sfm_pairs, features, matches, image_list=references\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ea3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = viz_3d.init_figure()\n",
    "viz_3d.plot_reconstruction(\n",
    "    fig, model, color=\"rgba(255,0,0,0.5)\", name=\"mapping\", points_rgb=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478094d",
   "metadata": {},
   "source": [
    "We also visualize which keypoints were triangulated into the 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(model, images, color_by=\"visibility\", n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b08268",
   "metadata": {},
   "source": [
    "# Localization\n",
    "Now that we have a 3D map of the scene, we can localize any image. To demonstrate this, we download [a night-time image from Wikimedia](https://commons.wikimedia.org/wiki/File:Paris_-_Basilique_du_Sacr%C3%A9_Coeur,_Montmartre_-_panoramio.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f07f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://upload.wikimedia.org/wikipedia/commons/5/53/Paris_-_Basilique_du_Sacr%C3%A9_Coeur%2C_Montmartre_-_panoramio.jpg\"\n",
    "# try other queries by uncommenting their url\n",
    "# url = \"https://upload.wikimedia.org/wikipedia/commons/5/59/Basilique_du_Sacr%C3%A9-C%C5%93ur_%285430392880%29.jpg\"\n",
    "# url = \"https://upload.wikimedia.org/wikipedia/commons/8/8e/Sacr%C3%A9_C%C5%93ur_at_night%21_%285865355326%29.jpg\"\n",
    "query = \"query/night.jpg\"\n",
    "!mkdir -p $images/query && wget $url -O $images/$query -q\n",
    "plot_images([read_image(images / query)], dpi=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a035ca4",
   "metadata": {},
   "source": [
    "Again, we extract features for the query and match them exhaustively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.main(\n",
    "    feature_conf, images, image_list=[query], feature_path=features, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pairs_from_exhaustive.main(loc_pairs, image_list=[query], ref_list=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2281689",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_features.main(\n",
    "    matcher_conf, loc_pairs, features=features, matches=matches, overwrite=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b037419",
   "metadata": {},
   "source": [
    "We read the EXIF data of the query to infer a rough initial estimate of camera parameters like the focal length. Then we estimate the absolute camera pose using PnP+RANSAC and refine the camera parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd559ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycolmap\n",
    "from hloc.localize_sfm import QueryLocalizer, pose_from_cluster\n",
    "\n",
    "camera = pycolmap.infer_camera_from_image(images / query)\n",
    "ref_ids = [model.find_image_with_name(r).image_id for r in references]\n",
    "conf = {\n",
    "    \"estimation\": {\"ransac\": {\"max_error\": 12}},\n",
    "    \"refinement\": {\"refine_focal_length\": True, \"refine_extra_params\": True},\n",
    "}\n",
    "localizer = QueryLocalizer(model, conf)\n",
    "ret, log = pose_from_cluster(localizer, query, camera, ref_ids, features, matches)\n",
    "\n",
    "print(f'found {ret[\"num_inliers\"]}/{len(ret[\"inliers\"])} inlier correspondences.')\n",
    "visualization.visualize_loc_from_log(images, query, log, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e5518",
   "metadata": {},
   "source": [
    "We visualize the correspondences between the query images a few mapping images. We can also visualize the estimated camera pose in the 3D map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c5533-f7b5-4e2c-ae62-de047abce7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = pycolmap.Image(cam_from_world=ret[\"cam_from_world\"])\n",
    "viz_3d.plot_camera_colmap(\n",
    "    fig, pose, camera, color=\"rgba(0,255,0,0.5)\", name=query, fill=True\n",
    ")\n",
    "# visualize 2D-3D correspodences\n",
    "inl_3d = np.array(\n",
    "    [model.points3D[pid].xyz for pid in np.array(log[\"points3D_ids\"])[ret[\"inliers\"]]]\n",
    ")\n",
    "viz_3d.plot_points(fig, inl_3d, color=\"lime\", ps=1, name=query)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
